#!/bin/bash  

#
# All atlases use 
#    docker.io/pyushkevich/ashs-base
# except for ASHS-PMC-T1 which uses:
#    docker.io/pyushkevich/ashs-t1-base
# and ASHS-PMC-7T-T1 which uses:
#    docker.io/longxie/ashs-7t-t1
#
# dss_ashs_run.sh is called the same for all Atlases
#    /app/dss_ashs_run.sh -w mywork -r /app/ashs -t $TicketId -a ${AtlasDir}
# except for ASHS-HarP which is called as:
#    /app/dss_ashs_run.sh -w mywork -r /app/ashs -t $TicketId -a ${SAtlasDir} -I $AtlasICVDir -g T1 -f T1 -L 101 -R 102 -J 100
#
# dss_ashs_run.sh pulls out the T1 and T2 layers, setups up the ASHS_HOOK_SCRIPT, and ASHS_HOOK_DATA 
#    ASHS_HOOK_DATA=$TicketID
#    [[ $ICV_ATLAS ]] && ASHS_HOOK_DATA+=",ASHS,0,0,0.5"
# and calls
#    $ASHS_ROOT/bin/ashs_main.sh -a $ASHS_ATLAS -g $T1_FILE -f $T2_FILE -w $WORKDIR/ashs -I $IDSTRING -H -P
#
# If doing ICV, Re-exports ASHS_HOOK_DATA and runs
#   $ASHS_ROOT/bin/ashs_main.sh -a $ICV_ATLAS -g $T1_FILE -f $T1_FILE -w $WORKDIR/ashs_icv -I $IDSTRING -H -P -B
#
# -P is to use GNU Parallel
# -B is to skip the initial registration and reuse results of initial joint label fusion
# -H use external hooks to report progress, errors and warnings
#
# dss_ashs_run.sh -L 101 -R 102 -J 100 =>
#   SHIFT_LEFT=101
#   SHIFT_RIGHT=102
#   SHIFT_ICV=100
# 

#
# Basic plan:
# Verify and convert inputs as needed
# Set correct git branch, master for most, ashs-t1 for ashs-pmc-t1
# Download the appropriate atlas
# Run ashs_main.sh
# Build itksnap file
# Deal with ASHS-HarP
#   Download atlas
#   Run ashs_main.sh
#   Add outputs to itksnap file
# Copy everything to the output directory


CmdName=$(basename "$0")

echo "$0 $@" 1>&2

function sys {
    [ -n "${opt_n}${opt_v}" ] && echo "$(date): $@" 1>&2
    [ -n "$opt_n" ] || "$@"
}

function installAshsAtlas {
        
    local Atlas="$1"
    local AtlasJson=$(jq -r 'select(.Atlas == "'"${Atlas}"'")' "$AshsAtlasConfigFile")

    local AtlasDirectory=$(echo "$AtlasJson" | jq -r '.Directory')
    local AtlasFile="${AshsAtlasesDir}/${Atlas}.tgz"
    local Url=$(echo "$AtlasJson" | jq -r '.Url')

    [ -d "$AtlasDirectory" ] || sys mkdir -p "$AtlasDirectory"

    [ -e "$AtlasFile" ] || sys time wget -q -O "$AtlasFile" "$Url" 

    [ -n "${opt_d}${opt_v}" ] && echo -n "Verifying '$Atlas' " 1>&2

    local md5Url=$(echo "$AtlasJson" | jq -r '.md5Url')
    local AtlasMd5Sum=$(sys wget -q -O - "$md5Url" | awk '{print $1}')

    local DownloadedMd5Sum=$(sys md5sum "$AtlasFile" | awk '{print $1}')

    if [ "$AtlasMd5Sum" == "$DownloadedMd5Sum" ]
    then
	[ -n "${opt_d}${opt_v}" ] && echo "Verified" 1>&2
    else
	[ -n "${opt_d}${opt_v}" ] && echo "Failed : '$AtlasMd5Sum' != '$DownloadedMd5Sum'" 1>&2

	echo "${CmdName} : Download of Atlas '${Atlas}' failed.  Bailing" 1>&2
	exit 1
    fi

    sys tar -xzf "$AtlasFile" -C "$AshsAtlasesDir" 
    
    echo "$AtlasJson"
}

sys apt install -y wget jq git time 
export ASHS_ROOT=/app/ashs
export PATH="${ASHS_ROOT}/bin":$PATH

AshsAtlasesDir="/app/atlas/data"
AshsAtlasConfigFile="/app/AshsAtlasesConfig.json"
ConfigJsonFile="config.json"
InputDir=${FLYWHEEL_INPUT}
OutputDir=${FLYWHEEL_OUTPUT}
TestDataDir=${FLYWHEEL}/testdata
TMPDIR=/tmp

RunDate=$(date +%Y-%m-%d_%H-%M)

SHIFT_LEFT=0
SHIFT_RIGHT=100
SHIFT_ICV=200

if [ ! -e "${ASHS_ROOT}/bin/identity.mat" ]
then
    
    cat << EOF > "${ASHS_ROOT}/bin/identity.mat"
1 0 0 0
0 1 0 0
0 0 1 0
0 0 0 1
EOF
fi

opt_v=-v

while getopts 1:2:c:dnq:tvw: arg
do

    case "$arg" in
	1|2|c|d|n|q|t|v|w)
	    eval "opt_${arg}='${OPTARG:=-${arg}}'"
	    ;;
    esac
done

shift $(($OPTIND - 1))

sys git clone 'https://github.com/brainsciencecenter/flywheel.git'
export PATH=${FLYWHEEL}:${FLYWHEEL}/flywheel/bin:$PATH
export PYTHONPATH=${FLYWHEEL}/flywheel/lib:$PYTHONPATH

sys sed -i 's,| bc,| /usr/bin/bc,' /app/ashs/bin/ashs_grid.sh
sys sed -i 's/^set -x /set /' $(grep -r '^set -x' /app/ashs | cut -f 1 -d ':')

[ -n "$opt_c" ] && ConfigJsonFile="$opt_c"

[ -n "$opt_d" ] && [ -e "$ConfigJsonFile" ] && jq -r . "$ConfigJsonFile"
[ -n "$opt_d" ] && find ${FLYWHEEL}

jq -r . "$ConfigJsonFile"

T1InputId=$(jq -r '.inputs.T1w.hierarchy.id' "$ConfigJsonFile")
ProjectId=$(fwget -1 "$T1InputId" | jq -r .parents.project)

if [ -z "$ProjectId" ]
then
	echo "${CmdName} : Could not get parent project id for '${T1InputId}'" 1>&2
	exit 1
fi

if [ -z "$opt_q" ]
then

	QaPlacement=$(jq -r '.config.QaPlacement' "$ConfigJsonFile")
	if [ -n "$QaPlacement" ]
	then
		opt_q="$QaPlacement"
	else
		opt_q=$(sys fwget -1 "$ProjectId" | jq -r '.info.AshsSettings.QaLocation')
	fi
fi

#
# Find the atlas list
#   Config file
#   Project default
#   Command args


if [ -e "$ConfigJsonFile" ]
then
	T1Input=$(jq -r '.inputs.T1w.location.path' "$ConfigJsonFile" | grep -v null)
        T1FileId=$(jq -r '.inputs.T1w.object.file_id' "$ConfigJsonFile" | grep -v null)
        T2Input=$(jq -r '.inputs.T2w.location.path' "$ConfigJsonFile" | grep -v null)
	Atlases=( $(jq -r '.config.ASHS_Atlases' "$ConfigJsonFile" | grep -v null | grep -v None) )
fi

[ -n "$opt_1" ] && T1Input="$opt_1"

if [ -z "$T1Input" ] || [ ! -e "$T1Input" ]
then
     echo "$CmdName : reqiured argument T1 missing. No -1 argument and not found in config.json" 1>&2
     echo "$syntax" 1>&2
     exit 3
fi

[ -z "$T2Input" ] && T2Input="$T1Input"
[ -n "$opt_2" ] && T2Input="$opt_2"

{
	read T1NiftiFile
	read T2NiftiFile
	read T1NiftiFileTrimmed
	read T1NiftiFileTrimmedSanitized
	read T2NiftiFileSanitized
} < <(sys ashsPrepT1T2Inputs $opt_n $opt_v -1 "$T1Input" -2 "$T2Input" -c "$ConfigJsonFile" )
	
if [ -z "$Atlases" ]
then
	Atlases=( $(sys fwget -1 "$ProjectId" | jq -r '.info.AshsSettings.DefaultAtlas' | sed 's/, */ /g') )
fi

if [ -n "$1" ] && [ "$1" == "all" ]
then
    Atlases=( $(jq -r '.Atlas' "$AshsAtlasConfigFile" | sort ) )
elif [ -n "$1" ]
then
    Atlases=( "$@" )
fi

#
# Make sure there is at least one atlas with json to back it up
#
Atlas="${Atlases[0]}"
AtlasJson=$(jq -r 'select(.Atlas == "'"${Atlas}"'")' "$AshsAtlasConfigFile")

if [ -z "$AtlasJson" ]
then   
    echo "${CmdName} : No valid Atlas supplied '$Atlas'" 1>&2
    echo "${CmdName} : Valid Atlases are: "1>&2
    jq -r '.Atlas' "$AshsAtlasConfigFile" 1>&2
fi

AnalysisId=$(jq -r '.destination.id' "$ConfigJsonFile" )
sys fwUpdate --update-fields "label=ashs - '${Atlases[*]}' on: $(date)" "$AnalysisId"


#IdString=$(basename "$T1NiftiFile" | sed -r 's/.gz$//; s/.zip$//; s/(.nii|.nifti|.dicom|.dcm)$//')
IdString=$(basename "$T2NiftiFile" | sed -r 's/.gz$//; s/.zip$//; s/(.nii|.nifti|.dicom|.dcm)$//')

for Atlas in "${Atlases[@]}"
do
	if [ -n "$opt_w" ]
	then
	    TmpDir=$opt_w
	    [ -d "$TmpDir" ] || sys mkdir "$opt_w"
	else
	    TmpDir=$(sys mktemp -d "/tmp/${Atlas}-wd-XXXXXX" )
	fi

        AtlasJson=$(installAshsAtlas "$Atlas")
        if [ -z "$AtlasJson" ]
	then
	    exit 1
	fi
	
	AtlasDirectory=$(echo "$AtlasJson" | jq -r '.Directory')
	AshsCmd=(
	    ashs_main.sh -a "$AtlasDirectory"  -g "$T1NiftiFileTrimmedSanitized" -f "$T2NiftiFileSanitized"  -w "$TmpDir"  -P
	)

	GitBranch="master"
	[ "$i" == "ASHS-PMC-T1" ] && GitBranch="ashs-t1"
	(cd "/app"; sys git checkout --recurse-submodules "$GitBranch" )

	#
	# *** Do we need to worry about ASHS_HOOK_SCRIPT/DATA ?
	#
	[ -d "$opt_d" ] || sys "${AshsCmd[@]}" || exit "$?"

	AshsPrefix=$(basename "$TmpDir")
	SnaplabelsInputTxtFile="${AtlasDirectory}/snap/snaplabels.txt"
	SnaplabelsOutputTxtFile="${OutputDir}/${IdString}_${Atlas}_snaplabels.txt"
	ItkSnapFile=${OutputDir}/${IdString}_${Atlas}_results.itksnap

	sys bash -x ./ashsFwResultsHandler $opt_v -a "$Atlas" -A "$AtlasDirectory" -c "$ConfigJsonFile" -i "$IdString" -o "$OutputDir" -l "$SHIFT_LEFT" -r "$SHIFT_RIGHT" -I "$SHIFT_ICV" -1 "$T1NiftiFile" -2 "$T2NiftiFile" -t "$T1NiftiFileTrimmed" -w "$TmpDir" -q "$opt_q" || exit "$?"

done

